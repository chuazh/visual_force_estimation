from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
import time
import numpy as np
#import pandas as pd
import tensorflow as tf
from RNN_Library import rnn_utils
from RNN_Library.Vanilla_LSTM import VanillaLSTMCell

class RNN_Regression:

    def __init__(self, config):

        # --------------------------------------------------------------------------------------------------------------
        # Values from configuration file
        # --------------------------------------------------------------------------------------------------------------

        # Summaries
        self.summaries_name_scope = config.summaries_name_scope

        # Learning rate
        self.learning_rate = config.learning_rate

        # Number of inputs, ouputs, hidden units, time steps, layers.
        self.number_inputs       = config.number_inputs
        self.number_outputs      = config.number_outputs
        self.number_hidden_units = config.number_hidden_units
        self.number_steps        = config.number_steps
        self.number_layers       = config.number_layers

        # Batch size
        self.batch_size = config.batch_size

        # Configuration (Max gradient norm)
        self.max_grad_norm = config.max_grad_norm
        
        # Enable to compute the gradient difference loss (GDL).
        self.enable_gdl_optimization = config.enable_gdl_optimization
        
        self.cell_type = config.cell_type

        self.custom_cell_type = config.custom_cell_type

        self.scale_data = {'X-Video': 1, 'X-Tool': 1, 'Y': 1}
        
        self.select_input_signals = {'X-Video': True, 'X-Tool': True}

        self.step_index = 1

        self.start_ouput_time_step = int(0.5 * self.number_steps)

        # --------------------------------------------------------------------------------------------------------------
        # Objects used by the computational graph
        # --------------------------------------------------------------------------------------------------------------

        # RNN: Initial state
        self.initial_state = None

        # RNN: Reset state
        self.reset_state = None

        # RNN State
        self.state = None

        # RNN Final state
        self.final_state = None

        # RNN Model
        self.cell = None

        # RNN Weights
        self.weights = None

        # RNN Biases
        self.biases = None

        # RNN Output
        self.outputs = None

        # RNN reduced output
        self.reduced_output = None

        # RNN last output
        self.last_output = None

        # Input/output
        self.X = None
        self.Y = None

        # Dropout probability
        self.P_dropout = None

        # Prediction
        self.prediction_op = None

        # Gradients
        self.Gradient_Y = None
        self.Gradient_Prediction =  None

        # Gradient difference loss
        self.gradient_difference_loss = None

        # Residual
        self.residual_op = None

        # Scaled residuals
        self.scaled_residual_op = None

        # L2 norm
        self.l2_norm = {
            'Residuals': None,
            'Ground Truth': None,
            'Prediction': None,
        }

        self.normalized_tensor = {
            'Ground Truth | Normalized': None,
            'Prediction | Normalized': None
        }

        # L1 norm
        self.l1_norm = {
            'Residuals': None,
            'Ground Truth': None,
            'Prediction': None
        }

        # Force Error Vector
        self.force_error_vector = {
            '6D Vector': None,
            'Fx': None,
            'Fy': None,
            'Fz': None,
            'Tx': None,
            'Ty': None,
            'Tz': None
        }

        # Absolute error
        self.absolute_error_op = None

        # Relative error
        self.relative_error_op = None

        # Root Mean Square (RMS) Error
        self.rms_error_op = None

        # Mean Absolute Error (MAE)
        self.mae_error_op = None

        # Weights for functions L2, GDL...
        self.lambda_l2  = 0.2
        self.lambda_gdl = 1.0 - self.lambda_l2

        # Gradients
        self.gradient_update_op = None

        # Cost
        self.cost_op = None
        self.cost_contributions = None
        self.cost_1 = None
        self.cost_2 = None
        self.cost_3 = None
        self.selected_cost_function = None
        self.dual_loss = None
        self.gradients = None

        # Accuracy operation
        self.accuracy_op = None

        # Optimizer
        self.optimizer = None

        # Training operation
        self.train_op = None

        # Epsilon constant
        self.epsilon = 1.0/100.0 # 1/625.0

        # Tolerance
        self.tolerance = 0.001

    def linear_layer(self, input_tensor, n_hidden, n_output, scope_name):

        with tf.variable_scope(scope_name):
            self.weights = tf.Variable(tf.random_normal([n_hidden, n_output]), name='weight')
            self.biases = tf.Variable(tf.random_normal([n_output]), name='bias')
            output = tf.matmul(input_tensor, self.weights) + self.biases

        return output

    def create_rnn_graph(self, X, P_dropout):

        print('[ RNN Regression ] Creating RNN Computational Graph -> Start')

        n_input = self.number_inputs
        n_output = self.number_outputs
        n_hidden = self.number_hidden_units
        n_steps = self.number_steps

        # --------------------------------------------------------------------------------------------------------------
        # Reshape input tensor X
        # --------------------------------------------------------------------------------------------------------------

        print('X Shape | Before Reshape Operation: ')
        print('  a) Tensor shape: ', X.get_shape())

        with tf.name_scope('input_data_reshape'):
            X = [tf.squeeze(input_, [1]) for input_ in tf.split(1, n_steps, X)]

        print('X Shape | After Reshape Operation:')
        print('  a) List size: ', len(X))
        print('  b) Tensor shape of each element in the list: ', X[0].get_shape())

        # --------------------------------------------------------------------------------------------------------------
        # RNN Graph definition
        # --------------------------------------------------------------------------------------------------------------

        with tf.name_scope('recurrent_neural_net'):


            # List of cells
            list_of_cells = self.number_layers * [None]

            # Lstm cell
            lstm_cell = None

            # Cell type string
            cell_type_string = ''
            
            # Custom LSTM cell type: 'CIFG', 'Complete'
            custom_lstm_cell_type = self.custom_cell_type
            
            for k in range(0, self.number_layers):
                
                # LSTM cell (from TF)
                if self.cell_type == 'LSTM-Tensorflow':
                    lstm_cell = tf.nn.rnn_cell.LSTMCell(
                        num_units=n_hidden,
                        input_size=None,
                        use_peepholes=True,
                        cell_clip=None,
                        initializer=None,
                        num_proj=None,
                        num_unit_shards=1,
                        num_proj_shards=1,
                        forget_bias=1.0
                    )
                    
                    cell_type_string = self.cell_type
                
                # GRU cell (from TF)
                elif self.cell_type == 'GRU-Tensorflow':
                    
                    lstm_cell = tf.nn.rnn_cell.GRUCell(num_units=n_hidden)
                    
                    cell_type_string = self.cell_type
                    
                # Custom LSTM
                elif self.cell_type == 'LSTM-Custom':
                    
                    cell_type_string = self.cell_type + ' | ' + custom_lstm_cell_type

                    # Vanilla LSTM Cell
                    if k == 0:
                        lstm_cell = VanillaLSTMCell(input_size=n_input, num_blocks=n_hidden, option=custom_lstm_cell_type)
                    else:
                        lstm_cell = VanillaLSTMCell(input_size=n_hidden, num_blocks=n_hidden, option=custom_lstm_cell_type)
    
                # Dropout layer.
                lstm_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_cell, output_keep_prob=P_dropout[k])
    
                # List of cells.
                list_of_cells[k] = lstm_cell
                
            # Multiple cells
            self.cell = tf.nn.rnn_cell.MultiRNNCell(list_of_cells)
            
            print('Cell Type = %s | Number of Layers = %d' % (cell_type_string, self.number_layers) )

            # Initial state
            self.initial_state = self.cell.zero_state(self.batch_size, tf.float32)

            # Reset state
            self.reset_state = self.cell.zero_state(self.batch_size, tf.float32)

            # Outputs and state
            self.outputs, self.state = tf.nn.rnn(
                cell=self.cell,
                inputs=X,
                initial_state=self.initial_state
            )

            # ----------------------------------------------------------------------------------------------------------
            # Reduced output: Average of output tensor Y
            # ----------------------------------------------------------------------------------------------------------

            No = len(self.outputs)
            out_tensor = None
            start_index = self.start_ouput_time_step  #int(0.5 * No)
            output_indices = range(start_index, No, 1)

            c = 0
            for i in output_indices:
                if i == start_index:
                    out_tensor = self.outputs[i]
                else:
                    out_tensor += self.outputs[i]
                c += 1

            self.reduced_output = out_tensor / c

            print('Output Tensor Y | Averaged over %d of %d time steps.' % (len(output_indices), No) )

            # ----------------------------------------------------------------------------------------------------------
            # Last output and final state
            # ----------------------------------------------------------------------------------------------------------

            # Last output of the recurrent neural net
            self.last_output = self.reduced_output

            # Final state
            self.final_state = self.state

        # --------------------------------------------------------------------------------------------------------------
        # Output layer
        # --------------------------------------------------------------------------------------------------------------

        # Linear output activation
        linear_activation = self.linear_layer(
            input_tensor=self.last_output,
            n_hidden=n_hidden,
            n_output=n_output,
            scope_name='output_layer'
        )

        print('[ RNN Regression ] Creating RNN Computational Graph -> End')

        return linear_activation

    def build_rnn(self):

        print('[ RNN Regression ] Build RNN -> Start')

        # --------------------------------------------------------------------------------------------------------------
        # Input/output tensor variables
        # --------------------------------------------------------------------------------------------------------------

        # RNN input (X)
        self.X = tf.placeholder("float", [self.batch_size, self.number_steps, self.number_inputs], name='X_input')

        # RNN output (Y)
        self.Y = tf.placeholder("float", [self.batch_size, self.number_outputs], name='Y_output')

        # Dropout probability
        self.P_dropout = tf.placeholder("float", [self.number_layers], name='P_drop')

        # Gradient of Y
        self.Gradient_Y = tf.placeholder("float", [self.batch_size, self.number_outputs], name='Y_gradient')

        # Gradient of Prediction
        self.Gradient_Prediction = tf.placeholder("float", [self.batch_size, self.number_outputs], name='Prediction_gradient')

        # --------------------------------------------------------------------------------------------------------------
        # Visualizing the input as a image summary
        # --------------------------------------------------------------------------------------------------------------

        with tf.name_scope('summaries'):
            tf.image_summary('rnn_input', tf.reshape(self.X, [self.batch_size, self.number_steps, self.number_inputs, 1]), 5)

        # --------------------------------------------------------------------------------------------------------------
        # Create the RNN computational graph
        # --------------------------------------------------------------------------------------------------------------

        self.prediction_op = self.create_rnn_graph(
            X=self.X,
            P_dropout=self.P_dropout
        )

        # --------------------------------------------------------------------------------------------------------------
        # Definition of losses and other measurements.
        # --------------------------------------------------------------------------------------------------------------

        with tf.name_scope('residual'):
            # Residual r = (Y_predicted - Y_ground_truth) / TOL
            self.residual_op = self.Y - self.prediction_op

        with tf.name_scope('relative_error'):
            # Relative error
            self.relative_error_op = tf.abs(self.residual_op) / tf.constant(self.tolerance)

        with tf.name_scope('rms_error'):
            self.rms_error_op = tf.sqrt(
                tf.reduce_mean(tf.square(self.residual_op), reduction_indices=1),
                name='root_mean_square_error'
            )

        with tf.name_scope('mae_error'):
            self.mae_error_op = tf.reduce_mean(
                tf.abs(self.residual_op),
                reduction_indices=1,
                name='mean_absolute_error'
            )

        with tf.name_scope('gradient_difference_loss'):
            self.gradient_difference_loss = tf.reduce_sum(
                tf.abs( tf.abs(self.Gradient_Y) - tf.abs(self.Gradient_Prediction) ),
                reduction_indices=1,
                name='gradient_difference_loss'
            )

        with tf.name_scope('force_error_per_component'):

            # Similarity per force component
            self.force_error_vector['6D Vector'] = tf.sqrt(
                tf.reduce_sum(tf.square(self.residual_op), reduction_indices=0), name='6d_error_vector')

            force_string = ['Fx', 'Fy', 'Fz', 'Tx', 'Ty', 'Tz']

            for index in range(0, len(force_string)):
                self.force_error_vector[force_string[index]] = self.force_error_vector['6D Vector'][index]

        with tf.name_scope('l2_norm'):

            # Similarity between force vectors
            self.l2_norm['Ground Truth'] = tf.sqrt(tf.reduce_sum(tf.square(self.Y), reduction_indices=1), name='l2_norm_ground_truth')
            self.l2_norm['Prediction']   = tf.sqrt(tf.reduce_sum(tf.square(self.prediction_op), reduction_indices=1), name='l2_norm_prediction')
            self.l2_norm['Residuals']    = tf.sqrt(tf.reduce_sum(tf.square(self.residual_op), reduction_indices=1), name='l2_norm_residuals')

        with tf.name_scope('l1_norm'):

            # Similarity between force vectors
            self.l1_norm['Residuals'] = tf.reduce_sum(tf.abs(self.residual_op), reduction_indices=1,name='l1_norm_residuals')

        with tf.name_scope('loss_contributions'):

            if self.enable_gdl_optimization:
                print('[ RNN Regression ] Gradient Difference Loss Optimization -> Enabled')
            else:
                print('[ RNN Regression ] Gradient Difference Loss Optimization -> Disabled')

            print('  a) Weight for L2 cost: ', self.lambda_l2)
            print('  b) Weight for GDL cost: ', self.lambda_gdl)

            with tf.name_scope('cost_1_loss_rms'):
                # L2 loss (RMS Error)
                self.cost_1 = tf.reduce_sum( tf.log( tf.square(self.rms_error_op) + self.epsilon) - tf.log(self.epsilon) )

            with tf.name_scope('cost_2_loss_gdl'):
                # Gradient difference loss (GDL)
                self.cost_2 = tf.reduce_sum( tf.log( tf.square( self.gradient_difference_loss ) + self.epsilon ) - tf.log(self.epsilon) )

            # Total Cost = L2 loss + Gradient Difference Loss
            self.cost_contributions = self.lambda_l2 * self.cost_1 + self.lambda_gdl * self.cost_2

        with tf.name_scope('cost'):
            self.cost_op = self.cost_contributions

        with tf.name_scope('accuracy'):

            # Accuracy: Mean Relative Error
            self.accuracy_op = tf.reduce_mean( self.relative_error_op, name='accuracy')

        # --------------------------------------------------------------------------------------------------------------
        # Define objects for training and optimize the RNN
        # --------------------------------------------------------------------------------------------------------------

        with tf.name_scope('optimizer'):

            # Trainable variables
            tvars = tf.trainable_variables()

            # Gradients
            self.gradients = tf.gradients(self.cost_op, tvars)

            # Gradients
            grads, _ = tf.clip_by_global_norm(
                self.gradients,
                self.max_grad_norm
            )

            #grads, _ = tf.clip_by_global_norm(
            #    tf.gradients(self.cost_op, tvars),
            #    self.max_grad_norm
            #)

            # Optimizer
            self.optimizer = tf.train.RMSPropOptimizer(learning_rate=self.learning_rate)

            # Trainable object
            self.train_op = self.optimizer.apply_gradients(zip(grads, tvars))


        # --------------------------------------------------------------------------------------------------------------
        # summaries
        # --------------------------------------------------------------------------------------------------------------

        with tf.name_scope('summaries'):

            # Cell output
            No = len(self.outputs)
            samples = 16
            if No < 16:
                samples = No
            indices_vector = np.linspace(0, No - 1, samples, dtype=int)
            for i in indices_vector:
                tf.histogram_summary('cell_'+str(No)+'/output_' + str(i), self.outputs[i])

            tf.histogram_summary('cell/reduced_output', self.last_output)
            tf.histogram_summary('cell/state', self.final_state)

            # Network output
            tf.histogram_summary('output/activation', self.prediction_op)
            tf.histogram_summary('output/weights', self.weights)
            tf.histogram_summary('output/bias', self.biases)

            # Root Mean Square Error (Force Vector): 6D Vector
            tf.histogram_summary('force_error/Force_Vector', self.force_error_vector['6D Vector'])
            tf.scalar_summary('force_error/Fx', self.force_error_vector['Fx'])
            tf.scalar_summary('force_error/Fy', self.force_error_vector['Fy'])
            tf.scalar_summary('force_error/Fz', self.force_error_vector['Fz'])
            tf.scalar_summary('force_error/Tx', self.force_error_vector['Tx'])
            tf.scalar_summary('force_error/Ty', self.force_error_vector['Ty'])
            tf.scalar_summary('force_error/Tz', self.force_error_vector['Tz'])

            # Cost
            tf.scalar_summary('cost', self.cost_op)

            # Accuracy: Mean Relative Error (MRE)
            tf.scalar_summary('accuracy/mean_relative_error', self.accuracy_op)

            # Similarity between predicted and ground truth vectors:
            # a) L1 norm
            # b) L2 norm
            tf.histogram_summary('residuals/l1_norm', self.l1_norm['Residuals'])
            tf.histogram_summary('residuals/l2_norm', self.l2_norm['Residuals'])

            # Residuals:
            #   a) Mean Relative Error (MRE)
            #   b) Root Mean Square Error (RMSE)
            #   c) Mean Absolute Error (MAE)
            #   d) Gradient difference loss.
            tf.histogram_summary('residuals/mean_relative_error', self.relative_error_op)
            tf.histogram_summary('residuals/root_mean_square_error', self.rms_error_op)
            tf.histogram_summary('residuals/mean_absolute_error', self.mae_error_op)
            tf.histogram_summary('residuals/gradient_difference_loss', self.gradient_difference_loss)

            # Gradients updates for optimizing the cost function
            No = len(self.gradients)
            step = 1
            indices_vector = np.arange(0, No, step, dtype=int)
            for i in indices_vector:
                tf.histogram_summary('gradients_'+ str(No) + '/variable_' + str(i), self.gradients[i])

        print('[ RNN Regression ] Build RNN -> End')

    def evaluate_rnn(self,
        session,
        path_vector,
        total_nodes,
        node_samples,
        camera_number_vector,
        dataset_obj,
        batch_size,
        dataset_type='Training',
        print_msg=True
        ):

        # RNN time steps
        time_steps_for_rnn = self.number_steps

        # Count number of evaluations
        iteration = 0

        # Total accuracy
        total_accuracy = 0

        total_accuracy_6d_vector = None

        # Total RMSE
        total_mean_relative_error = total_accuracy

        # Initialize cell state
        # cell_state = self.initial_state.eval()
        cell_state = self.reset_state.eval()

        # Dropout probability
        dropout_probability = np.ones((self.number_layers,), dtype=float)

        print('[ RNN Evaluation | %s Set ] Total Accuracy | Mean Relative Error Per Batch: %0.4f ' % (dataset_type, total_mean_relative_error))

        # --------------------------------------------------------------------------------------------------------------
        # Loop over total paths
        # --------------------------------------------------------------------------------------------------------------

        for current_path_index in xrange(total_nodes[dataset_type]):

            # Select a path as index
            select_path_index = path_vector[dataset_type][current_path_index]

            # Total samples in current path (node)
            current_node_samples = node_samples[dataset_type][select_path_index]

            # Create a time vector

            '''
            time_vector = rnn_utils.get_time_vector_for_rnn_evaluation(
                current_node_samples=current_node_samples,
                batch_size=batch_size,
                time_steps_for_rnn=time_steps_for_rnn,
                datset_type=dataset_type,
                params=(total_nodes['Training'], total_nodes['Test'], num_batches_eval_training)
            ) '''

            time_vector = np.arange(0, current_node_samples - batch_size - time_steps_for_rnn, batch_size, dtype=int)

            # Total number of batches
            TOTAL_BATCHES = len(time_vector)

            # ----------------------------------------------------------------------------------------------------------
            # Loop over total cameras
            # ----------------------------------------------------------------------------------------------------------

            for camera_number in camera_number_vector:

                if self.select_input_signals['X-Video']:
                    # Load matrix of feature vectors extracted from video frames for the current camera number
                    dataset_obj.load_feature_vectors_extracted_from_frames(
                        setup_number=dataset_obj.samples_per_node[dataset_type][select_path_index, dataset_obj.COLUMN['Setup Number']],
                        data_number=dataset_obj.samples_per_node[dataset_type][select_path_index, dataset_obj.COLUMN['Data Number']],
                        camera_number=camera_number,
                        feature_vector_matrix_type='RNN Evaluation',
                        print_msg=True
                    )

                # ------------------------------------------------------------------------------------------------------
                # Loop over total batches
                # ------------------------------------------------------------------------------------------------------

                for b in xrange(TOTAL_BATCHES):

                    # Start index to create a batch of data
                    start_index_batch = time_vector[b]

                    # End index to create a batch of data
                    end_index_batch = start_index_batch + batch_size

                    # Last sample in the batch
                    last_sample_in_the_batch = end_index_batch + time_steps_for_rnn

                    # Check if the last sample in the batch can be reached
                    IS_DATA_VALID = last_sample_in_the_batch < current_node_samples

                    if IS_DATA_VALID:

                        # ----------------------------------------------------------------------------------------------
                        # Get batch of data
                        # ----------------------------------------------------------------------------------------------

                        batch_x, batch_y = dataset_obj.get_batch_of_data(
                            start_index=start_index_batch,
                            batch_size=batch_size,
                            step_index=self.step_index,
                            dataset_type=dataset_type,
                            matrix_index=select_path_index,
                            select_input_signals=self.select_input_signals,
                            scale_signals=self.scale_data,
                            feature_vector_matrix_type='RNN Evaluation',
                            print_msg=False
                        )

                        # ----------------------------------------------------------------------------------------------
                        # Compute accuracy
                        # ----------------------------------------------------------------------------------------------

                        feed_data_test = {
                            self.X: batch_x,
                            self.Y: batch_y,
                            self.P_dropout: dropout_probability,
                            self.initial_state: cell_state
                        }

                        accuracy_value, accuracy_matrix, cell_state = session.run([self.accuracy_op, self.relative_error_op, self.final_state], feed_dict=feed_data_test)

                        if iteration == 0:
                            total_accuracy_6d_vector = np.sum(accuracy_matrix, axis=0)
                        else:
                            total_accuracy_6d_vector += np.sum(accuracy_matrix, axis=0)

                        # Accumulating the accuracy:
                        total_accuracy += accuracy_value

                        # ----------------------------------------------------------------------------------------------
                        # Display messages
                        # ----------------------------------------------------------------------------------------------

                        # Messages
                        values_1 = (
                            dataset_type,
                            iteration,
                            current_path_index, total_nodes[dataset_type] - 1, select_path_index,
                            camera_number,
                            current_node_samples
                        )

                        values_2 = (b, TOTAL_BATCHES - 1, start_index_batch, end_index_batch)
                        values_3 = (accuracy_value, total_accuracy)
                        string_1 = "[ RNN Evaluation | %s Set ][ Iteration %d ][ Path %d/%d -> %d ][ Camera %d ][ Samples %d ]" % values_1
                        string_2 = "[ Batch %d/%d | Start Index %d - End Index %d ]" % values_2
                        string_3 = " Mean Relative Error (MRE) Per Batch -> Current Batch | Accumulated = %0.4f | %0.4f " % values_3

                        if print_msg:
                            print(string_1 + string_2 + string_3)

                        iteration += 1

                    else:

                        if print_msg:
                            print(string_1 + string_2 + " Invalid Data ! -> Discarding batch for evaluation.")

        # Compute the mean relative error per batch as the final error.
        total_mean_relative_error = total_accuracy / iteration

        total_mean_relative_error_per_force_component = (total_accuracy_6d_vector/iteration)

        # Print the final error on the output console.
        print('[ RNN Evaluation | %s Set ] Total Accuracy | Mean Relative Error (MRE) in the current set: %0.4f ' % (dataset_type, total_mean_relative_error) )

        # Delete matrix of feature vectors used for RNN Evaluation in order to save memory.
        dataset_obj.feature_vector_matrix['RNN Evaluation'] = None

        return total_mean_relative_error, total_mean_relative_error_per_force_component

    def inference(self,
        session,
        path_vector,
        total_nodes,
        node_samples,
        camera_number_vector,
        dataset_obj,
        batch_size,
        percentage_samples_inference=None,
        dataset_type='Test',
        save_inference_files = None,
        enable_save_inference_files = False,
        print_msg=True
        ):

        # Recurrent neural net time steps
        time_steps_for_rnn = self.number_steps

        # Count number of times inference is performed
        iteration = 0

        # Initialize cell state
        cell_state = self.initial_state.eval()

        # Force data structure
        force = {
            'Predicted': None,
            'Ground Truth': None,
            'Matrix': None,
        }

        # Dropout probability
        dropout_probability = np.ones((self.number_layers,), dtype=float)

        print('[ RNN Inference | %s Set ] Start' % dataset_type )

        # ----------------------------------------------------------------------------------------------------------
        # Loop over every path = [ Path 0, Path 1, ..., Path N_path ]
        # ----------------------------------------------------------------------------------------------------------

        for current_path_index in xrange(total_nodes[dataset_type]):

            # Select a path as index
            select_path_index = path_vector[dataset_type][current_path_index]

            # Total samples in current path (node)
            current_node_samples = node_samples[dataset_type][select_path_index]

            # Last sample in the time vector
            LAST_TIME_STEP = current_node_samples-batch_size-time_steps_for_rnn

            # Total number of time vector samples
            time_vector = np.arange(
                start=0,
                stop=LAST_TIME_STEP,
                step=batch_size,
                dtype=int
            )

            # Total number of batches in the current path
            TOTAL_BATCHES = len(time_vector)

            # ----------------------------------------------------------------------------------------------------------
            # Loop over total cameras = [ 1, 2, 3, 4 ]
            # ----------------------------------------------------------------------------------------------------------

            for camera_number in camera_number_vector:

                if self.select_input_signals['X-Video']:
                    # Load matrix of feature vectors extracted from video frames for the current camera number
                    dataset_obj.load_feature_vectors_extracted_from_frames(
                        setup_number=dataset_obj.samples_per_node[dataset_type][select_path_index, dataset_obj.COLUMN['Setup Number']],
                        data_number=dataset_obj.samples_per_node[dataset_type][select_path_index, dataset_obj.COLUMN['Data Number']],
                        camera_number=camera_number,
                        feature_vector_matrix_type='RNN Inference',
                        print_msg=True
                    )

                # ------------------------------------------------------------------------------------------------------
                # Loop over total batches = [ Batch 0, Batch 1, ..., Batch N_batch ]
                # ------------------------------------------------------------------------------------------------------

                for b in xrange(TOTAL_BATCHES):

                    # Start index to create a batch of data
                    start_index_batch = time_vector[b]

                    # End index to create a batch of data
                    end_index_batch = start_index_batch + batch_size

                    # Last sample in the batch
                    last_sample_in_the_batch = end_index_batch + time_steps_for_rnn

                    # Check if the last sample in the batch can be reached
                    IS_DATA_VALID = last_sample_in_the_batch < current_node_samples

                    if IS_DATA_VALID:

                        # ----------------------------------------------------------------------------------------------
                        # Get batch of data
                        # ----------------------------------------------------------------------------------------------

                        batch_x, batch_y = dataset_obj.get_batch_of_data(
                            start_index=start_index_batch,
                            batch_size=batch_size,
                            step_index=self.step_index,
                            dataset_type=dataset_type,
                            matrix_index=select_path_index,
                            select_input_signals=self.select_input_signals,
                            scale_signals=self.scale_data,
                            feature_vector_matrix_type='RNN Inference',
                            print_msg=False
                        )

                        # ----------------------------------------------------------------------------------------------
                        # Ground Truth Force
                        # ----------------------------------------------------------------------------------------------

                        force['Ground Truth'] = batch_y

                        # ----------------------------------------------------------------------------------------------
                        # Predicted Force
                        # ----------------------------------------------------------------------------------------------

                        feed_data_inference = {
                            self.X: batch_x,
                            self.P_dropout: dropout_probability,
                            self.initial_state: cell_state
                        }

                        force['Predicted'], cell_state = session.run(
                            [self.prediction_op, self.final_state],
                            feed_dict=feed_data_inference
                        )

                        # ----------------------------------------------------------------------------------------------
                        # Concatenate vectors in one matrix
                        # ----------------------------------------------------------------------------------------------

                        force_submatrix = np.concatenate(
                            (force['Predicted'], force['Ground Truth']),
                            axis =1
                        )

                        if b == 0:
                            force['Matrix'] = force_submatrix
                        else:
                            force['Matrix'] = np.concatenate( (force['Matrix'], force_submatrix), axis=0 )

                        # ----------------------------------------------------------------------------------------------
                        # Display messages
                        # ----------------------------------------------------------------------------------------------

                        # Values to update and display
                        values_1 = (
                            dataset_type,
                            iteration,
                            current_path_index, total_nodes[dataset_type]-1, select_path_index,
                            camera_number,
                            current_node_samples
                        )

                        values_2 = (
                            b, TOTAL_BATCHES-1,
                            start_index_batch, end_index_batch
                        )

                        string_1 = "[ RNN Inference | %s Set ][ Iteration %d ][ Path %d/%d -> %d ][ Camera %d ][ Samples %d ]" % values_1
                        string_2 = "[ Batch %d/%d | Start Index %d - End Index %d ] Force = [ fx, fy, fz, tx, ty, tz ]" % values_2

                        if print_msg:
                            print(string_1 + string_2)
                            print('   [ a ] Force Vector [ Predicted | Ground Truth ]: ')
                            print(force_submatrix[0, :])

                        iteration += 1

                    else:

                        if print_msg:
                            print(string_1 + string_2 + " Invalid Data ! -> Discarding batch for inference.")

                # ------------------------------------------------------------------------------------------------------
                # Save a matrix of predicted force and ground truth per camera (in a single matrix)
                # in the specified path and file.
                # ------------------------------------------------------------------------------------------------------

                if enable_save_inference_files:

                    # Setup number
                    setup_number = dataset_obj.samples_per_node[dataset_type][select_path_index, dataset_obj.COLUMN['Setup Number']]

                    # Data number
                    data_number = dataset_obj.samples_per_node[dataset_type][select_path_index, dataset_obj.COLUMN['Data Number']]

                    # Camera number
                    camera_number = camera_number

                    # Path + filename definition in which to store the inference matrices.
                    values = (setup_number, data_number, camera_number)
                    file_string = save_inference_files['Path'] + '/' + save_inference_files['Filename']
                    file_to_save = file_string % values

                    # Save the inference matrix on disk.
                    np.save(
                        file=file_to_save,
                        arr=force['Matrix']
                    )

                    if print_msg:
                        print('[ Inference Matrix ] Saved as a .npy file.')
                        print('   [ a ] File -> %s' % file_to_save)
                        print('   [ b ] Matrix Shape -> (%d, %d)' % force['Matrix'].shape)

                # Clean the current matrix
                force['Matrix'] = None

        # Print the final error on the output console.
        print('[ RNN Inference | %s Set ] End' % dataset_type)

        # Delete matrix of feature vectors used for RNN Evaluation in order to save memory.
        dataset_obj.feature_vector_matrix['RNN Inference'] = None



